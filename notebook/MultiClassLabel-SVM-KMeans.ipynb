{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568   \n",
       "1    -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303   \n",
       "2    -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498   \n",
       "4    -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ...  0.069430  0.071001  0.021591   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.061127  0.068978  0.017745   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.082474  0.077771 -0.009688   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.051796  0.069073  0.017963   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.061455  0.072983 -0.003980   \n",
       "\n",
       "      MFCCs_20  MFCCs_21  MFCCs_22  Family  Genus  Species  RecordID  \n",
       "0     0.057684  0.118680  0.014038       3      0        0         1  \n",
       "1     0.020140  0.082263  0.029056       3      0        0         1  \n",
       "2    -0.025083  0.099108  0.077162       3      0        0         1  \n",
       "3    -0.054766 -0.018691  0.023954       3      0        0         1  \n",
       "4    -0.031346  0.108610  0.079244       3      0        0         1  \n",
       "...        ...       ...       ...     ...    ...      ...       ...  \n",
       "7190  0.052449 -0.021860 -0.079860       2      7        9        60  \n",
       "7191  0.046461 -0.015418 -0.101892       2      7        9        60  \n",
       "7192  0.027834 -0.000531 -0.080425       2      7        9        60  \n",
       "7193  0.041803 -0.027911 -0.096895       2      7        9        60  \n",
       "7194  0.031560 -0.029355 -0.087910       2      7        9        60  \n",
       "\n",
       "[7195 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "family_label_encoder = preprocessing.LabelEncoder()\n",
    "family_label_encoder.fit(df['Family'])\n",
    "genus_label_encoder = preprocessing.LabelEncoder()\n",
    "genus_label_encoder.fit(df['Genus'])\n",
    "species_label_encoder = preprocessing.LabelEncoder()\n",
    "species_label_encoder.fit(df['Species'])\n",
    "df['Family'] = family_label_encoder.transform(df['Family'])\n",
    "df['Genus'] = genus_label_encoder.transform(df['Genus'])\n",
    "df['Species'] = species_label_encoder.transform(df['Species'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-4].to_numpy()\n",
    "y = df.iloc[:, -4:-1].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a classifier for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exact Match:__ Calculate subset accuracy meaning the prdeicted set of labels should exactly match with the true set of labels.<br>\n",
    "__Hamming Loss:__ The fraction of the wrong labels to the total number of labels.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaissianSVC_best_paras(X, y):\n",
    "    best_score = float('-inf')\n",
    "    best_c = None\n",
    "    best_gamma = None\n",
    "    for c in c_range:\n",
    "        for gamma in gamma_range:\n",
    "            score = 0\n",
    "            kf = KFold(n_splits=10)\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                cur_X_train, cur_X_val = X[train_index], X[test_index]\n",
    "                cur_y_train, cur_y_val = y[train_index], y[test_index]\n",
    "\n",
    "                clf = OneVsRestClassifier(SVC(kernel='rbf', random_state=42, gamma=gamma, C=c))\n",
    "                clf.fit(cur_X_train, cur_y_train)\n",
    "                score += clf.score(cur_X_val, cur_y_val)\n",
    "            cur_score = score / 10\n",
    "            if cur_score > best_score:\n",
    "                best_score = cur_score\n",
    "                best_c = c\n",
    "                best_gamma = gamma\n",
    "    return best_score, best_c, best_gamma\n",
    "\n",
    "c_range = np.logspace(start=-3, stop=6, num=5, base=10)\n",
    "gamma_range = np.linspace(start=0.1, stop=2, num=5)\n",
    "family_loss, family_c, family_gamma = gaissianSVC_best_paras(X_train, y_train[:, 0])\n",
    "genus_loss, genus_c, genus_gamma = gaissianSVC_best_paras(X_train, y_train[:, 1])\n",
    "species_loss, species_c, species_gamma = gaissianSVC_best_paras(X_train, y_train[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family label: weight of the SVM penalty = 2.000000 , width of the Gaussian Kernel = 31.622777\n",
      "Genus label: weight of the SVM penalty = 2.000000 , width of the Gaussian Kernel = 31.622777\n",
      "Species label: weight of the SVM penalty = 1.525000 , width of the Gaussian Kernel = 31.622777\n"
     ]
    }
   ],
   "source": [
    "print(\"Family label: weight of the SVM penalty = %f , width of the Gaussian Kernel = %f\" % (family_gamma, family_c))\n",
    "print(\"Genus label: weight of the SVM penalty = %f , width of the Gaussian Kernel = %f\" % (genus_gamma, genus_c))\n",
    "print(\"Species label: weight of the SVM penalty = %f , width of the Gaussian Kernel = %f\" % (species_gamma, species_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian kernel SVM's exact match score: 0.990736 \n",
      "Gaussian kernel SVM's hamming loss: 0.006948 \n"
     ]
    }
   ],
   "source": [
    "def train_on_best(cur_X, cur_y, cur_X_test, gamma, c):\n",
    "    clf = OneVsRestClassifier(SVC(kernel='rbf', random_state=42, gamma=gamma, C=c))\n",
    "    clf.fit(cur_X, cur_y)\n",
    "    return clf.predict(cur_X_test)\n",
    "\n",
    "family_predicts = train_on_best(X_train, y_train[:, 0], X_test, family_gamma, family_c)\n",
    "genus_predicts = train_on_best(X_train, y_train[:, 1], X_test, genus_gamma, genus_c)\n",
    "species_predicts = train_on_best(X_train, y_train[:, 2], X_test, species_gamma, species_c)\n",
    "final_predicts = np.column_stack((family_predicts, genus_predicts, species_predicts))\n",
    "gaussian_exact_match = np.all(final_predicts == y_test, axis=1).mean()\n",
    "gaussian_hamming_loss = np.sum(np.not_equal(y_test, final_predicts)) / float(y_test.size)\n",
    "print(\"Gaussian kernel SVM's exact match score: %f \" % gaussian_exact_match)\n",
    "print(\"Gaussian kernel SVM's hamming loss: %f \" %gaussian_hamming_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeat 1(b)ii with L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1SVC_best_paras(X, y):\n",
    "    best_score = float('-inf')\n",
    "    best_c = None\n",
    "    for c in c_range:\n",
    "        score = 0\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            cur_X_train, cur_X_val = X[train_index], X[test_index]\n",
    "            cur_y_train, cur_y_val = y[train_index], y[test_index]\n",
    "\n",
    "            clf = OneVsRestClassifier(LinearSVC(penalty='l1', random_state=42, C=c, dual=False))\n",
    "            clf.fit(cur_X_train, cur_y_train)\n",
    "            score += clf.score(cur_X_val, cur_y_val)\n",
    "        cur_score = score / 10\n",
    "        if cur_score > best_score:\n",
    "            best_score = cur_score\n",
    "            best_c = c\n",
    "    return best_score, best_c\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_standardized = scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "c_range = np.logspace(start=-3, stop=6, num=5, base=10)\n",
    "family_loss, family_c = l1SVC_best_paras(X_train_standardized, y_train[:, 0])\n",
    "genus_loss, genus_c = l1SVC_best_paras(X_train_standardized, y_train[:, 1])\n",
    "species_loss, species_c = l1SVC_best_paras(X_train_standardized, y_train[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family label: weight of the L1 SVM penalty = 31.622777\n",
      "Genus label: weight of the L1 SVM penalty = 31.622777\n",
      "Species label: weight of the L1 SVM penalty = 31.622777\n"
     ]
    }
   ],
   "source": [
    "print(\"Family label: weight of the L1 SVM penalty = %f\" % (family_c))\n",
    "print(\"Genus label: weight of the L1 SVM penalty = %f\" % (genus_c))\n",
    "print(\"Species label: weight of the L1 SVM penalty = %f\" % (species_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_best_l1(cur_X, cur_y, cur_X_test, c):\n",
    "    clf = OneVsRestClassifier(LinearSVC(penalty='l1', random_state=42, C=c, dual=False))\n",
    "    clf.fit(cur_X, cur_y)\n",
    "    return clf.predict(cur_X_test)\n",
    "\n",
    "family_predicts = train_on_best_l1(X_train_standardized, y_train[:, 0], X_test_standardized, family_c)\n",
    "genus_predicts = train_on_best_l1(X_train_standardized, y_train[:, 1], X_test_standardized, genus_c)\n",
    "species_predicts = train_on_best_l1(X_train_standardized, y_train[:, 2], X_test_standardized, species_c)\n",
    "final_predicts = np.column_stack((family_predicts, genus_predicts, species_predicts))\n",
    "l1_exact_match = np.all(final_predicts == y_test, axis=1).mean()\n",
    "l1_hamming_loss = np.sum(np.not_equal(y_test, final_predicts)) / float(y_test.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 linear SVM's exact match score: 0.909217 \n",
      "L1 linear SVM's hamming loss: 0.058515 \n"
     ]
    }
   ],
   "source": [
    "print(\"L1 linear SVM's exact match score: %f \" % l1_exact_match)\n",
    "print(\"L1 linear SVM's hamming loss: %f \" %l1_hamming_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Repeat 1(b)iii by using SMOTE or any other method for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "f_X_train, f_y_train = oversample.fit_resample(X_train_standardized, y_train[:, 0])\n",
    "g_X_train, g_y_train = oversample.fit_resample(X_train_standardized, y_train[:, 1])\n",
    "s_X_train, s_y_train = oversample.fit_resample(X_train_standardized, y_train[:, 2])\n",
    "family_loss, family_c = l1SVC_best_paras(f_X_train, f_y_train)\n",
    "genus_loss, genus_c = l1SVC_best_paras(g_X_train, g_y_train)\n",
    "species_loss, species_c = l1SVC_best_paras(s_X_train, s_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family label: weight of the L1 SVM penalty with SMOTE = 5623.413252\n",
      "Genus label: weight of the L1 SVM penalty with SMOTE = 31.622777\n",
      "Species label: weight of the L1 SVM penalty with SMOTE = 31.622777\n"
     ]
    }
   ],
   "source": [
    "print(\"Family label: weight of the L1 SVM penalty with SMOTE = %f\" % (family_c))\n",
    "print(\"Genus label: weight of the L1 SVM penalty with SMOTE = %f\" % (genus_c))\n",
    "print(\"Species label: weight of the L1 SVM penalty with SMOTE = %f\" % (species_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_predicts = train_on_best_l1(f_X_train, f_y_train, X_test_standardized, family_c)\n",
    "genus_predicts = train_on_best_l1(g_X_train, g_y_train, X_test_standardized, genus_c)\n",
    "species_predicts = train_on_best_l1(s_X_train, s_y_train, X_test_standardized, species_c)\n",
    "final_predicts = np.column_stack((family_predicts, genus_predicts, species_predicts))\n",
    "l1_exact_match_SMOTE = np.all(final_predicts == y_test, axis=1).mean()\n",
    "l1_hamming_loss_SMOTE = np.sum(np.not_equal(y_test, final_predicts)) / float(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 linear SVM's exact match score with SMOTE: 0.863826 \n",
      "L1 linear SVM's hamming loss with SMOTE: 0.073954 \n"
     ]
    }
   ],
   "source": [
    "print(\"L1 linear SVM's exact match score with SMOTE: %f \" % l1_exact_match_SMOTE)\n",
    "print(\"L1 linear SVM's hamming loss with SMOTE: %f \" % l1_hamming_loss_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Report your conclusions about the classifiers you trained. <br>\n",
    "Ans: Looks like gaussian kernal SVM has the best result, and for the two L1 penalized SVM, without SMOTE has a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMean_X = df.iloc[:, :-4].to_numpy()\n",
    "kMean_y = df.iloc[:, -4:-1].to_numpy()\n",
    "kMean_y_f = df.iloc[:, -4].to_numpy()\n",
    "kMean_y_g = df.iloc[:, -3].to_numpy()\n",
    "kMean_y_s = df.iloc[:, -2].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKmeans(k, training_data):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(training_data)\n",
    "    cluster_labels = kmeans.predict(training_data)\n",
    "    ch_index = calinski_harabasz_score(X, cluster_labels)\n",
    "\n",
    "    return cluster_labels, ch_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Determine which family is the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_majority(members):\n",
    "    vote_count = collections.Counter(members)\n",
    "    return vote_count.most_common(1)[0][0]\n",
    "\n",
    "def determine_label(predicts_clusters, true_labels):\n",
    "    cluster_members = collections.defaultdict(list)\n",
    "    label_match = {}\n",
    "    for index, cluster in enumerate(predicts_clusters):\n",
    "        cluster_members[cluster].append(true_labels[index])\n",
    "\n",
    "    for clus, members in cluster_members.items():\n",
    "        label_match[clus] = find_majority(members)\n",
    "    \n",
    "    predict_labels = [label_match[i] for i in predicts_clusters]\n",
    "    return np.array(predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculate the average Hamming distance, Hamming score, and Hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_result(predicts, truth):\n",
    "    hamming_dis = np.sum(np.not_equal(truth, predicts))/float(predicts.size)*3\n",
    "    hamming_score = 1 - np.sum(np.not_equal(truth, predicts))/float(predicts.size)\n",
    "    hamming_loss = np.sum(np.not_equal(truth, predicts)) / float(predicts.size)\n",
    "    return hamming_dis, hamming_score, hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Monte-Carlo Simulation: Perform the following procedures 50 times, and report the average and standard deviation of the 50 Hamming Distances that you calculate.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_list = []\n",
    "score_list = []\n",
    "loss_list = []\n",
    "for _ in range(50):\n",
    "    best_ch = float('-inf')\n",
    "    best_k = None\n",
    "    # Determine best k\n",
    "    for k in range(2, 51):\n",
    "        cluster_labels, ch = runKmeans(k, kMean_X)\n",
    "        if ch > best_ch:\n",
    "            best_ch = ch\n",
    "            best_k = k\n",
    "\n",
    "    # Determine label by best k mean\n",
    "    cluster_labels, ch = runKmeans(best_k, kMean_X)\n",
    "    f_predict_labels = determine_label(cluster_labels, kMean_y_f)\n",
    "    g_predict_labels = determine_label(cluster_labels, kMean_y_g)\n",
    "    s_predict_labels = determine_label(cluster_labels, kMean_y_s)\n",
    "\n",
    "    # Hamming result\n",
    "    final_predicts = np.column_stack((f_predict_labels, g_predict_labels, s_predict_labels))\n",
    "    hamming_dis, hamming_score, hamming_loss = hamming_result(final_predicts, kMean_y)\n",
    "    dis_list.append(hamming_dis)\n",
    "    score_list.append(hamming_score)\n",
    "    loss_list.append(hamming_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average for hamming distance:  0.895621959694232\n",
      "Average for hamming score:  0.7014593467685891\n",
      "Average for hamming loss:  0.29854065323141077\n",
      "Std for hamming distance:  1.1102230246251565e-16\n",
      "Std for hamming score:  1.1102230246251565e-16\n",
      "Std for hamming loss:  5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "print('Average for hamming distance: ', np.mean(np.array(dis_list)))\n",
    "print('Average for hamming score: ', np.mean(np.array(score_list)))\n",
    "print('Average for hamming loss: ', np.mean(np.array(loss_list)))\n",
    "\n",
    "print('Std for hamming distance: ', np.std(np.array(dis_list)))\n",
    "print('Std for hamming score: ', np.std(np.array(score_list)))\n",
    "print('Std for hamming loss: ', np.std(np.array(loss_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
